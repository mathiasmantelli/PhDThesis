\chapter{Related Work}
\label{chap:3_related_work}

The work in this thesis is closely related to two major research topics: OS approaches and spatio-temporal models of the environment. This chapter focuses on discussing the published works that aim to deal with these topics and that have been considered to develop this thesis. 

\section{Object Search approaches}
\label{sec:3_object_search_approaches}
The OS problem has been studied for many years in the robotics field. The proposed approaches range from multi-agent collaborating to search for an object~\cite{Ye1996Collaborative}, to a single robot actively performing a semantic-based search~\cite{Zeng2020Semantic}. After many years subtopics of research arose within the OS, such as Indirect and Active Visual searches. Despite this long period in which new approaches have been proposed, for the best of our knowledge, no detailed surveys in the literature shed light on this latter subtopic. However, it is possible to find comprehensive surveys on wider topics such as salient objects detection~\cite{Borji2019Salient}, visual attention \cite{Begum2010Visual}, and as pointed out by Aydemir et al.~\cite{Aydemir2013Active}, active vision~\cite{Chen2011Active,Chung2011Search}. It is important to mention that even though it has not been proposed as a survey, Aydemir et al. presented a comprehensive review of some of the most important works related to OS~\cite{Aydemir2013Active}. Hence, we review other works not presented in~\cite{Aydemir2013Active}, that are as important to the development of this thesis as the presented ones. This review allows us to show how this thesis compares to the visual OS body of research. It also shows how our contributions push the state-of-the-art further.

Previous works have investigated the OS task in numerous ways and based on different sorts of data. Ye and Tsotsos proposed one of the first works to deal with OS~\cite{Ye1999Sensor}, in which they provided a sensor planning system. They argued that the robot should change the sensing parameters to bring the target object into the camera's field of view. The proposed system was formulated as an optimization problem, i.e., maximize the probability of detecting the object with minimum overall cost. Hence, a robot equipped with a camera that could pan, tilt, and zoom, was used throughout their experiments. They decomposed the space of possible actions into a finite set to determine the sensing actions. The next action was selected based on comparing the likelihood of detecting the target object and the action cost. They have successfully achieved their goal with better performance than those OS strategies with fixed action sequences.

In a series of papers, Aydemir and colleagues also explored the advantages of an adjustable visual sensor in the context of OS tasks~\cite{Aydemir2011Plan, Aydemir2011Object, Aydemir2011Search, Aydemir2013Active}. In~\citet{Aydemir2011Object}, the authors proposed a spatial representation that consists of tree sub-representations. The first one is a 3D metric map used for obstacle avoidance, path planning, and viewpoint selection for object search. The second is a topological map, also called place map, that maintains the environment's topology. The last one is a conceptual map, which integrates all these other maps to infer the category of each place based on the room shape (elongated and square) and appearance (office-like, meeting room-like). Besides, the authors also proposed a planner for the OS based on the spatial relationships between objects and the environment (e.g., table IN kitchen or book ON table). First, it decides the overall search strategy based on the spatial representation (which objects should be found in which location). Then it computes a subset of all possible sensing actions that are most likely to bring the target object into the robot's field of view. In~\citet{Aydemir2011Search}, it was used part of the contributions presented in~\citet{Aydemir2011Object}. The spatial relation previously introduced was used here as the basis of their new strategy for an OS approach. They argue that the spatial relation is useful for OS tasks since it reduces the search space. If the OS system is aware of the relation \textit{book ON table}, the search space reduces to the table area. The same applies for the case of \textit{cup IN kitchen}, in which the search space is only the kitchen. Besides reusing the spatial relation concept, the authors also proposed the idea of grouping the spatial relations, i.e., \textit{book ON table IN kitchen} in the case of the previous example. Their outcome was a strategy that can obtain near-optimal search behavior to find the target object. In~\citet{Aydemir2011Plan}, it was proposed another OS approach, but for the first time using semantic spatial knowledge. Despite the hierarchical planner that is quite similar to the other works already present, the biggest novelty is the high-level conceptual and semantic information from the environment used on their OS approach. Semantic cues were used to guide the object search process, in which its semantic room category represents each discrete place from the environment. Due to the combination of low-level sensor percept and this high-level representation from semantic cues, the hierarchical planner efficiently performed the OS task. The advantages of using semantic information in OS tasks encouraged \citet{Aydemir2011Plan} to propose another OS work. In~\citet{Aydemir2013Active}, the authors proposed an OS approach for large unknown environments, and hence, the proposed system had to balance between exploring the environment to gain more information or perform the OS. Further, while exploring the environment, their approach guided the robot towards more promising unknown areas according to the robot's knowledge since its first movement. In terms of the strategy for searching the object, the authors proposed a planner that considers four actions: move, process view, calculate views, and search object. The first moves the robot to the desired place. The second one moves the robot to a viewpoint and runs an object detection algorithm on the image taken by the robot. The third calculates a set of viewpoints in a single room, aiming to point the camera towards the most promising objects within the room. The last one forms a subproblem for their planner whose the set of actions consists of move and process view to search for an object in a single room. For performing the presented actions, the planner also considers the semantic cues from the appearance, geometry, and topology of the environment and combines it with general semantic knowledge of indoor spaces to reason about locations of interest.  

These works aforementioned were designed as a searching function that minimizes the search cost. Each action of moving either the robot or the camera has a cost, and the goal is to find the target object with the lowest total cost. In~\citet{Aydemir2012ExploitingAnd}, the authors fixed the robot's visual sensor, reducing the complexity of the searching function. The authors presented the 3D context idea: the correlation between local 3D structure and object placement in everyday scenes. They use the local 3D shape around objects as a signal of the placement of these objects. The advantage is that their approach can capture more complex 3D contexts without implementing specialized routines for the robot. Instead of looking for the object itself, they first find the places that are more likely to contain the object. Their results show that the local structure surrounding the target objects is a suitable indicator of object placement in scenes. Besides, their OS approach accurately predicted the location of the everyday objects included in the study. Lastly, the 3D context present in this work is machine learning-based, and hence, their OS approach has to be trained in every new environment to incorporate the singularities of the place. Therefore, the local information about how the objects relate to the 3D context must be known beforehand. Similarly to~\citet{Aydemir2012ExploitingAnd} that made their RGB-D dataset publicly available, in~\cite{Aydemir2012What} Aydemir et al. also published a dataset called KTH. In this case, the dataset is composed of a set of floor plans that encompasses, in total, 37 buildings, 165 floors, and 6248 rooms. In addition to KTH, another contribution of their work was two methods for predicting indoor topologies and room categories given a partial map of the environment. The goal was to predict what lies ahead in the topology of the environment through its topology.

The idea of relying on significant and visible landmarks to optimize the search was not used only in~\cite{Aydemir2012ExploitingAnd}. Zeng et al. exploited background knowledge about common spatial relationships between landmarks and target objects~\cite{Zeng2020Semantic}. Their proposal, called Semantic Linking Maps (SLiM), maintained the belief over the locations of the target object and the landmark. Simultaneously, it accounted for probabilistic inter-object spatial relations. In contrast to the 3D context-based OS systems, Rasouli et al. proposed an attention-based OS system~\cite{Rasouli2020Attention}. They argued that an OS system must be responsive, directive, spatiotemporal, and efficient, which are the characteristics addressed by their model. It embedded visual attention in an n-step decision-making algorithm formalized as a 1st-order Markov process. The use of visual attention increased the robot's awareness of the environment. Hence, they used all relevant available visual information, leveraging the spatial and appearance information about the object. Rasouli and Tsotsos also relied on visual attention methods to reduce computational costs on their robotic visual search~\cite{Rasouli2017Integrating}. They proposed a three-pronged probabilistic search algorithm that incorporated three forms of visual attention: viewpoint selection, saliency, and object-based models. On their model, attention is used to generate maps with highlighted areas in the image which are more likely to contain an object of interest. The experiments showed that the proposed three-tier attention framework decreased the search cost in terms of distance traveled, search time, and the number of actions taken. Saidi et al. explored a different robot than the other works that opted for wheeled robots since their OS system was proposed based on the specificities of a humanoid robot~\cite{Saidi2007Active}. A visibility map, which constrains the sensor parameter space, was used to avoid unnecessary calls to the rating function that evaluates the interest of a potential next view through the analysis of the theoretical field of view.

The object's surroundings provide a significant benefit for OS approaches. In~\citet{Chen2013Visual}, it was proposed an OS approach for cluttered environments that are challenging scenarios due to the partial occlusion of objects by other ones. Some objects may be only half visible in such scenarios, and the authors' proposal used the object's surrounding and spatial constraints to aid the searching. As the authors argue, usually objects are neatly placed to fulfill many functional purposes, and hence, the searching space can be substantially reduced even before the start of the OS. The proposed approach works in two phases. The first one is recognition, in which data is acquired to find out the number of objects in the scene and which map cells have a high probability of finding the objects. Both the object's 2D and 3D features are used for its recognition. The second one aims to generate an action for every candidate cell in the map and select the best one to be executed. Despite the promising ideas and results, Chen and Lee assume that the sizes, heights, locations, orientations, and accessible angles of all objects surrounding the target object are known in advance. Besides, they also assume these characteristics will not change throughout the searching process. 
 
\citet{Sprute2017Ambient} proposed a complete system to support the elderly in their home environments. The system includes a service robot and a camera network to make the older person's home smart. The main proposal of this work is to use the camera network to benefit the service robot in performing the OS task, besides expanding the total area analyzed by visual sensors. The cameras in the environment reduce the searching space for the service robot and overcome the robot's sensor limitation. The hierarchical search system proposed by the authors consists of three layers: local search, global search, and exploration. The local search is activated when the object is within the robot's field of view. The global search is activated if the robot does not find the object locally, and here the environmental cameras are used. If these two first layers cannot locate the object, the robot explores the environment looking for it. Due to the substantial advantage of the camera network and the smart home integration with the service robot, the proposed system managed to find the objects within the environment during the experiments efficiently. 

In~\citet{Wang2018Efficient}, the authors claim that if the robot behaves like a human in OS tasks, the searching efficiency and quality could be improved. Besides, they also argue that the semantic information of the entities in the environment could fill the gap between humans and the intelligent robot, so the robot could be trained by the typical human's knowledge to clarify the relations among entities. In light of this, they formulated the OS problem as a Partially Observable Markov Decision Process (POMDP), which is an idiomatic framework for modeling decision-making under uncertainty. The belief distribution of their custom POMDP was trained considering the semantic information of the room types and the objects. Besides the custom POMDP, the authors also proposed a graph structure called Belief Road Map (BRM), built along with the searching process in the unknown environment. The BRM is supposed to efficiently provide a path for the robot instead of using the whole grid map to estimate the path for the search. 

It is worth mentioning that part of this thesis considers the exploration of unknown environments as part of the OS problem. We aim to perform OS in an entire unknown search space, which requires switching between the exploration of unknown regions and the exploitation in already known regions. Hence, it is important to discuss some works related to exploration. Here, they are divided into two significant groups regarding their goals. First, strategies that aim to explore the whole environment, usually finishing when the robot has visited the entire free area \cite{Quattrini2016ASemantically, Girdhar2014Curiosity}. Second, goal-directed strategies that aim to reach a goal, such as searching for an object, a room, or a person. 

Some of these exploration-based OS approaches use a semantic map, whereas others use semantic properties from objects. %The system proposed by Aydemir et al. \cite{Aydemir2013Active} focuses on a large-scale environment, where the robot should find objects using mainly visual sensing. They affirm that rather than performing an exhaustive search in the area, their system could find the object guiding the robot towards areas more likely to contain it. The probability is calculated considering extracted semantic cues from appearance, geometry, the topology of the environment, and general semantic knowledge of the indoor space. They showed that the results improved drastically after including a semantic description in their search system.
%Differently, 
The framework proposed by Veiga et al. \cite{Veiga2016Efficient} searches for objects in domestic environments. It is composed of a system that perceives the query object in RGB-D images through inference and sensor information. The outcome of this process, called knowledge, is saved and updated in a semantic map. Experiments in a realistic apartment have shown that their framework worked well in practice, presenting a reliable and efficient search approach. 

Another significant work that searches objects in domestic scenarios is Rogers' et al. \cite{Rogers2013Robot}. In contrast to \cite{Veiga2016Efficient} that proposed a modular system, their approach considered the context of the environment. A graph, connecting places and objects within these places, is used to predict objects' presence (or absence) based on the room categories. The reasoning over the graph, combined with a planner, is used to perform an object search task. Experiments showed that the robot was able to find objects in the environment.

Talbot et al. \cite{Talbot2016Find} and Schulz et al. \cite{Schulz2015Robot} proposed navigation approaches that are also goal-directed, despite not being exploration ones. The idea of an original and abstract map that links symbolic spatial information with observed symbolic information and actual places in the real world was firstly introduced by \cite{Schulz2015Robot}. This map is used to make inferences about the location of places. Later, Talbot et al. \cite{Talbot2016Find} extended the idea of the abstract maps, proposing a novel method that defines the topological structure and spatial layout information encoded in spatial language phrases. The system has shown to complete the task by traveling slightly further than the optimal path.

Despite the good outcomes from the solutions presented by the papers mentioned above, there is still room for improvements. In~\cite{Aydemir2013Active} Aydemir et al. depended on prior semantic knowledge about indoor spaces obtained from databases. Talbot et al. \cite{Talbot2016Find} and Schulz et al.\cite{Schulz2015Robot} depended on a priori abstract maps. Veiga et al. \cite{Veiga2016Efficient} required beforehand information to learn about objects and the environment. Additionally, it used a 3D recognition-based framework from the Point Cloud Library (PCL) for object recognition, which is computationally expensive. Rogers et al. \cite{Rogers2013Robot} also implemented PCL to segment data from RGB-D sensor, continuing to cluster the points, which is a heavy workload for computers. It is also important to highlight that none of them has explored the benefits of textual information available in the environment. 

In contrast to the works that rely on semantic information to improve the robot's performance in OS tasks,~\citet{Rasouli2020Attention} proposed a system that guides the robot towards the target object using the relevant stimuli provided by the robot's visual sensor. Visual attention techniques are used to extract visual information from the environment actively. In combination with a non-myopic decision-making algorithm, the author's proposal leads the robot to search more relevant areas of the environment to find the target object. The results indicate that visual attention improves the searching process, but it also depends on the nature of the OS task and the complexity of the environment.

\section{Spatio-Temporal models}
Most of the works proposed by the research community in Mobile Robotics ignore or filter the changes in the environment since they are considered noise and only disturb the estimations. The idea of modeling and incorporating the environmental changes into different robotic solutions is relatively new. Below we present the works based on spatial-temporal information, which most inspired this chapter work in terms of modeling the environment changes.

In~\citet{Krajnik2014Long}, it was proposed a topological localization approach for service robots in dynamic indoor environments. It explicitly uses information about environment changes by learning and modeling the spatio-temporal dynamics of the robot's area. First, the robot learns the changes in the surroundings of each pre-defined location over one week, and it models the changes using the proposed spectral representation. Then, when the robot estimates its position within the map, it tries to match its current observation to the predicted representations of each location's surroundings for that specific time. According to the authors, the proposed localization approach can predict environmental changes in time, allowing the robot's localization improvement during long-term operations in populated environments. However, the authors assume that the environment's appearance is affected by a set of hidden, periodic processes in mid- to long-term perspective, and that the environment's dynamics can be described by the frequency, amplitude, and time shift of these processes.
 
Besides the localization field, the time and environment changes were also considered within the human-robot interaction field.~\citet{Vintr2019Spatio} introduced a spatio-temporal representation for service robots to anticipate the human presence in human-populated environments. Their proposal aims to model periodic and temporal patterns of people's presence, considering their routines and habits. The proposed representation projects the time onto a set of wrapped dimensions representing the periodicities of people's presence, and hence, it can make long-term predictions of human presence. These predictions allow service robots to schedule their tasks in a more suitable way not to bother humans.  

\citet{Krajnik2020Chronorobotics} explored the Chronorobotics, a new area introduced by them, that studies the experiences that autonomous systems can gather when observing human-populated environments for an extended period of time. The goal in Chronorobotics is to provide robots capable of adapting to naturally cyclic dynamics of the human-populated environments. Their work proposed methods that introduce the notion of dynamics into spatial environment models, which end up in representations that provide service robots the ability to anticipate future states of changing environments. 

Narayana, Kolling and Fong use a semantic map as the user-facing interface on their fleet of floor-cleaning robots~\cite{Barayana2020Lifelong}. They argue that these robots may operate in dynamic environments, and hence, it is necessary to enable the mapping to lifelong applications. They update their map based on the changes in the environment, keeping only the most updated version of the semantic map, overwriting the past versions. They use algorithms to detect when there are conflicts in the update of the semantic map, and to resolve them with an additional map layers called map-meta with additional meta-semantics. Their semantic map represents classes such as walls, rooms and doors.

The last work discussed in this section is another work proposed by ~\citet{Krajnik2015Where}.%, and for the best of our knowledge, the only published work by the research community that has used spatio-temporal models for OS tasks as we are aiming to do. 
The authors argue that in human-populated environments, the object locations are impacted by human activities that tend to exhibit daily and weekly periodicities. Hence, identifying and modeling these periodicities generates a more accurate representation of possible object locations, thus reducing the search space. Their search is formulated as a path planning problem in partially known environments, in which the probability of object occurrences at particular regions is a function of time. A traditional topological map represents the probability of object locations. Each node is associated with a temporal model that represents the dynamics of the object occurrence at the particular location. The experiments in different datasets show that explicit representation of the long-term periodicities of environment dynamics speed up the search process due to the search space reduction. Despite the promising results, the work has two assumptions. First, the topology of the environment where the robot is operating has to be known in advance. Second, the target object locations are influenced by human activities that exhibit a certain degree of periodicity. 

\section{Semantic map and heat map}
Despite not proposing an OS system, Pangergic et al. introduced an representation and acquisition of Semantic Objects Maps (SOM$^+$), which provides information for autonomous SRs~\cite{Pangercic2012Semantic}. Their SOM$^+$ represent all the furniture entities of kitchen environments including cupboards, electrical devices, tables, counters, positions, appearances, and articulation models. In addition to the objects' pose, it also includes the appearance and articulation of furniture objects, so the robot can perform fetch and place tasks more efficiently. Lastly, the area of operation limits to kitchens, where the robot can manipulate drawers, doors, cupboards, and other objects.

A second non-OS work that it is worth to mention here is the one proposed by Oksanen et al.~\cite{Oksanen2015Methods}. They use a heat map to highlight the most popular places to do sports in a given region, and it was applied to public cycling workouts to represent the density of the trajectories and the diversity of the users. They only register the trajectory that has been taken by the cyclist, not matter when (day or hour) the user was working out.

\section{A discussion on the Related Works}
There are several aspects of our thesis that push it beyond the current state of the art, summarized in Table~\ref{tab:works_summarized}. Compared to most of the OS works discussed within this section, ours considers the organisation of the environment as search cues and does not ignore the environmental changes over a period of time. The works proposed by Krajn{\'\i}k and colleagues have shown that it is possible to model the environment changes, and spatial-temporal-based approaches present considerable improvements and robustness. What sets our thesis aside from~\citet{Krajnik2015Where}, for example, is that we do not assume that the object's location exhibit a certain degree of periodicity. Besides, it is not necessary to collect data for an extended period to then start the search. Instead, our proposals do not require any pattern or periodicity. Besides, they do not require any data beforehand, which helps their deployment in practice. This is a considerable advantage compared to the works that demand the environment's map, object-object relation (or object-place relation), or the information about the target object's geometry or color.

%Our proposed OS system reads the door sign numbers through an efficient computer vision algorithm and analyses them to decide whether the current path is promising for the robot to find the goal-door. It does not require an environment description or other instruction in advance, suitable for tasks in unknown environments. Additionally, it is not computationally expensive, and a simple computer and two cameras embedded in a robot can execute it. Relying on textual information from the environment and inferring semantic information is another contribution of our work compared to the other papers reviewed here. Given that no information or map is necessary for our system, it is a good solution for entirely unknown environments.

\begin{landscape}
\begin{table}[]
\caption[Table comparing OS and spatial-temporal works.]{Table comparing OS and spatial-temporal works.}
\label{tab:works_summarized}
\makebox[\linewidth]{
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|}
\cline{2-10}
                       & \begin{tabular}[c]{@{}c@{}}Object\\ Search\end{tabular} & \begin{tabular}[c]{@{}c@{}}Environment  \\ map in advance\end{tabular} & \begin{tabular}[c]{@{}c@{}}Object location \\ knowledge\end{tabular} & \begin{tabular}[c]{@{}c@{}}Object-object\\ relation\end{tabular} & \begin{tabular}[c]{@{}c@{}}Object-place\\ relation\end{tabular} & \begin{tabular}[c]{@{}c@{}}Spatio-\\ temporal\end{tabular} & \begin{tabular}[c]{@{}c@{}}Object\\ knowledge\end{tabular} & \begin{tabular}[c]{@{}c@{}}Periodicity\\ dependence\end{tabular}  & \begin{tabular}[c]{@{}c@{}}Long-term\\ application\end{tabular}   \\ \hline
\multicolumn{1}{|r|}{\cite{Ye1999Sensor}}              & \checkmark & - & - & - & - & - & - & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Aydemir2011Object}}         & \checkmark & - & - & - & \checkmark & - & - & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Aydemir2011Plan}}           & \checkmark & - & - & - & \checkmark & - & - & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Aydemir2011Search}}         & \checkmark & \checkmark & - & \checkmark & \checkmark & - & \checkmark & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Aydemir2012ExploitingAnd}}  & \checkmark & - & - & - & \checkmark & - & \checkmark & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Aydemir2013Active}}         & \checkmark & - & - & - & \checkmark & - & - & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Chen2013Visual}}            & \checkmark & - & - & - & \checkmark & - & - & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Sprute2017Ambient}}         & \checkmark & - & - & - & - & - & - & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Wang2018Efficient}}         & \checkmark & - & - & - & \checkmark & - & - & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Rasouli2020Attention}}      & \checkmark & - & - & - & - & - & - & - & - \\ \hline
\multicolumn{1}{|r|}{\cite{Krajnik2014Long}}           & - & \checkmark & - & - & - & \checkmark & \checkmark & \checkmark & \checkmark \\ \hline
\multicolumn{1}{|r|}{\cite{Vintr2019Spatio}}           & \checkmark & - & - & - & - & \checkmark & - & \checkmark & \checkmark \\ \hline
\multicolumn{1}{|r|}{\cite{Krajnik2020Chronorobotics}} & - & - & - & - & - & \checkmark & - & \checkmark & \checkmark \\ \hline
\multicolumn{1}{|r|}{\cite{Krajnik2015Where}}          & \checkmark & \checkmark & - & - & - & \checkmark & - & \checkmark & \checkmark \\ \hline
\multicolumn{1}{|r|}{Ours}                             & \checkmark & - & - & - & - & \checkmark & - & - & \checkmark \\ \hline
\end{tabular}
}
\end{table}
\end{landscape}