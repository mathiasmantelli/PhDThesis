\chapter{Introduction}
The first decades of research in Mobile Robotics, from the beginning until 2004, handled the challenges of connecting efficiency and data association. They introduced probabilistic formulations to path planning, exploration, simultaneous localization and mapping (SLAM), and many other areas. Some of the approaches from these areas are still popular nowadays, such as RaoBlackwellised Particle Filters and Extended Kalman Filters. The majority of them were based on ultrasonic or lidar sensors, as these were the most popular and robust sensors at the time. Consequently, the outcome maps were mostly 2D grid ones, in which the cells represented the free, occupied (obstacles), and unknown regions~\cite{Cesar2016Simultaneous}. 

After building a solid foundation for many problems with probabilistic approaches, the research community took a forward step. They concentrated on improving the properties of the already proposed and new approaches like observability, convergence, and consistency~\cite{Cesar2016Simultaneous}.
Simultaneously in this period (2004-2015), visual sensors have been in the spotlight as an alternative to gain information about the environment. Their considerable improvement in data quality and variety (e.g., depth images, point clouds, stereo images) aided their increasing employment. In fact, building 2D and 3D maps with a visual sensor resulted in a new term, Visual SLAM~\cite{Salas2014Dense}. 

Mobile robotics have enjoyed formidable advantages in performing tasks that only expect robots to navigate through free spaces and avoid obstacles. Moving items from point A to point B or vacuuming free spaces are examples of robotics tasks with satisfactory solutions. However, the same level of success does not apply so far to many other high-level tasks that robots are supposed to dealing with nowadays. Since mobile robotics shifted its focus from factory floors and assembly lines to everyday living spaces, robots are demanded to perform human-like tasks in different scenarios that are not necessarily as strict, neat, and organized as the industrial world~\cite{Aydemir2012Exploiting}. Relying only on purely geometric maps and perceptions do not allow the mobile robotics going beyond basic representations, which restricts the robot to obtain a high-level understanding of the environment. This might be the reason for robots not prosper as much in high-level tasks. %We believe that one of the reasons for robots not prospering as much in high-level tasks is relying only on purely geometric maps and having limited perceptions that do not allow going beyond basic geometry representations to obtain a high-level understanding of the environment.  
The robots are deprived of processing the environmental data to infer or estimate extra valuable knowledge useful in various tasks. 


\section{Hypothesis and Goals}
As aforementioned, high-level robotics tasks demand the robots to read the environment similarly to humans, which reason over many characteristics of the room or objects and not only over the size of the free or occupied areas. The robot's geometric perception, i.e., raw sensor readings that generate standard geometric maps, is not descriptive and informative enough for providing such improvement demanded by the high-level tasks. This limitation does not mean that geometric maps are useless or irrelevant these days. On the contrary, they are still helpful and significant for the robot's safety navigation or path planning. However, there is a demand for complementing and extending the robot's geometric perception with meaningful knowledge from the environment. We then claim that the high-level information inferred from the sensor readings, also called semantic information, must be heavily exploited to complement the robot's perception when building autonomous robots.

The association of semantic information (or concepts) to geometric entities in the map is called semantic mapping, one of the newest topics the researchers have explored. It enhances the robot's autonomy and robustness in many ways, besides facilitating some challenging tasks~\cite{Cesar2016Simultaneous}. Autonomous cars are a great example of a robotic application that demands a human-like understanding of the environment. Fig.~\ref{fig:waymo_point_cloud} depicts a point cloud from the Waymo's autonomous car while it is driving itself in the road. The raw point cloud does not differentiate the obstacles around the car since it only indicates where they are and which regions are free. If the car relies only on this point cloud, it can move by the road avoiding obstacles, but it is far from behaving like a proper driver following all traffic rules. Its geometric perception does not specify, for example, which obstacles are static (trees, curbs, or traffic plates) or dynamic (pedestrians, cyclists, or cars), which is vital for everyone's safety. However, with the aid of semantic information, the car's perception goes beyond just detecting objects such as traffic signs, cars, and people, Fig. ~\ref{fig:waymo_pedestrian_crossing_cars}. The car understands which traffic signs are open or closed by their color of their lights, where the cars are intended to go, and the type of the cars (regular or police), Fig.~\ref{fig:waymo_pedestrian_crossing_cars_traffic_light_paths}. Human drivers naturally and quickly understand the scene in Fig.~\ref{fig:waymo_clean_environment}, but the same can not be said about robots. 


\begin{figure}[h]
     \centering
     \begin{subfigure}[b]{0.493\columnwidth}
         \centering
         \includegraphics[width=\textwidth]{figs/waymo_point_cloud.png}
         \caption{}
         \label{fig:waymo_point_cloud}
     \end{subfigure}~~
     \begin{subfigure}[b]{0.49\columnwidth}
         \centering
         \includegraphics[width=\textwidth]{figs/waymo_clean_environment.png}
         \caption{}
         \label{fig:waymo_clean_environment}
     \end{subfigure}
     \\[.5em]     
     \begin{subfigure}[b]{0.49\columnwidth}
         \centering
         \includegraphics[width=\textwidth]{figs/waymo_pedestrian_crossing_cars.png}
         \caption{}
         \label{fig:waymo_pedestrian_crossing_cars}
     \end{subfigure}~~  
     \begin{subfigure}[b]{0.49\columnwidth}
         \centering
         \includegraphics[width=\textwidth]{figs/waymo_pedestrian_crossing_cars_traffic_light_paths.png}
         \caption{}
         \label{fig:waymo_pedestrian_crossing_cars_traffic_light_paths}
     \end{subfigure}
     \caption[Waymo's autonomous car driving itself in a city.]{\small Waymo's autonomous car driving itself in a city. The point cloud, (a), is read by one of its embedded sensors. At every moment, (b), the car detects all the surroundings objects, (c), and infers their meanings before making decisions, (d). Images taken from one of the videos from Waymo\footnotemark.}
     \label{fig:waymo_geometric_semantic}
 \end{figure}
%\footnote{https://www.youtube.com/watch?v=B8R148hFxPw}

We hypothesize that semantic information and semantic maps bridge the gap limiting mobile robotics from improving towards high-level tasks. Our idea is that the environment provides more information inferred by the robot's system than what the simple lidar, sonar, and camera sensors can read. As semantic information is more like a specific knowledge for each task and inferred from the robot's surroundings than a particular type of data from a sensor reading, several questions must be answered before using it in a robotic task. We see the following as noteworthy challenges\footnotetext{Waymo \ang{360} Experience: A Fully Autonomous Driving Journey. youtube.com/watch?v= B8R148hFxPw}: 
\begin{itemize}
	\item Deciding on what type of semantic information is possible to infer and associate to the robot's surroundings that is relevant to the task;
	\item How to perform the inferring or estimate the semantic information;
	\item How to use semantic information to improve the robot's performance in a particular task.
\end{itemize}

Since semantic information is relatively new in the literature, the first point is frequently discussed in the context of geometric information. Briefly, for the context of a robotic task, which is the information that is not explicitly available in the environment but could be inferred or estimated to improve the robot's performance? This demands a deep understanding of the task and the general environment characteristics where the robot operates. An inspiration for answering this point is to consider how humans reason under the same circumstance and solve such a task, and how we process the environment's information to accomplish the task efficiently. 

Second, depending on the needed semantic information, it may be necessary to use methods based on machine learning to estimate it. For example, training a deep learning model for estimating terrain traversability for an outdoor ground robot may provide a suitable result. However,  besides the training requirement, the solution's quality depends on the training data, and this approach does not scale well. Probabilistic-based estimations appear as a second option, as it does not require a large set of data for training, and accepts a wide range of different models.

The third and last point, the proper use of the inferred semantic information in the robot's system, is crucial for successful task completion. As the robot gains more information from the environment, it is important to keep updating the estimations, and it is even better if the estimations become more robust over time. 

The exploitation of semantic information in robotics is an idea that has recently gained attention from researchers, and thus, most of the challenging problems are still unsolved. A simple way of pushing the limits further and investigate these problems is to study the advantages of semantic information in different areas. In this thesis, we have chosen a task with a high difficulty level that can benefit from semantic information: object search (OS) in indoor and unknown environments, a yet unsolved problem in robotics. 

In OS tasks, the robot's goal is to find a target object in the environment with a visual sensor. Usually, the environment is unknown to the robot, and the data it uses for searching are gathered with its own sensors. Since we are complementing the robot's perception with semantic information models for different OS tasks, the extra knowledge from the environment inferred by the robot has to aid the OS searching by reducing the search space. The robot plans a search strategy that estimates the most promising regions to contain the target object. This thesis exploits the improvements in OS tasks by the use of semantic information inferred from two different data sources disregarded by the research community: text and dynamic obstacles. 

%The first years of research in the field of Mobile Robotics saw the introduction of many probabilistic formulations for SLAM, path planning,  
%-At the beginning, Robotics was interested in estimating the obstacle's positions and the free space in the environment (Robotics has started with robots operating in assembly lines in factories, and now it is shifting to everyday living spaces)
%
%
%
%-However, this field has evolved and expanded the varieties of places the robots operate
%-By operating in more different environment and developing many tasks, researchers started including many sensors to the robots in order to make it more capable of acquiring data
%-However, that is not necessary if we can process the sensor readings and estimate more information besides the raw data
%
%Robotics has been changing its focus from factory floors to everyday living spaces, such as offices, houses, hospitals, airports, and etc~\cite{Aydemir2012Exploiting}. 


\section{Contributions}
Parts of this thesis have been previously published or submitted as journal articles. The following publications are the results of research carried during this PhD:

\begin{enumerate}
	\item MANTELLI, M. et al. Temporal object search system based on heat maps. \textit{Journal of intelligent \& robotic systems} (in review), Springer, v. 101, n. 2, p. 1–23, 2021.\\
\textbf{	Summary and Individual contribution:} This paper is on how to search a target object in unknown and dynamic environments efficiently. As opposed to other OS works that consider the objects' position static and ignore the human-object interaction, the idea presented in this work is to incorporate a person's routine and habits in the search strategy. This work aimed to model the semantic information of how objects are moved over time within an environment and use the inferred information to reduce the searching space. This idea came from observing how the objects are placed over time and that every person has their own singularities in terms of object placement.
The contribution of the author of this thesis is in modeling the semantic information as part of the search strategy and in building a heat map with the inferred data.  

	\item MANTELLI, M. et al. Semantic active visual search system based on text information for large and unknown environments. \textit{Journal of intelligent \& robotic systems}, Springer, v. 101, n. 2, p. 1–23, 2021.\\
\textbf{	Summary and Individual contribution:} This paper is on how to find a target door label based on text analysis. Although humans heavily rely on texts for accomplishing several tasks, text as a data source is not very popular in robotics. In this work, we have argued that texts have a great potential for providing search clues and are often found in man-made environments. This idea came from the human behavior when searching for a someone's office in an unknown building, and how the door labels are used for estimating whether the current corridor is promising for finding the target office. The search strategy relies on the patterns of door labels in indoor scenarios and it reasons over them to estimate which corridor is more promising for achieving the goal.
	
\end{enumerate}

\section{Outline}
The outline of this thesis is as follows. First, in Chapter~\ref{chap:2_theoretical_background}, we introduce a background on the main problems in mobile robotics, as well as the most popular approaches that deal with each problem. Besides, this chapter also presents the general concepts of the OS problem, which is used throughout this thesis along with the basic concepts of mobile robotics. In Chapter~\ref{chap:3_text_os_system}, we provide our first semantic OS system that is based on text as the main source of semantic information. Next, in Chapter~\ref{chap:4_temporal_os_system}, we discuss our second semantic OS system, which is the one that aims to understand how the objects within the environment are moved through a period of time, to make predictions about their future positions. Lastly, in Chapter~\ref{chap:5_discussion_thesis_progress}, we conclude this thesis proposal by discussing the current contributions and draw the future directions for this PhD work.


%\begin{itemize}
%    \item \emph{cite}: Unicórnios são verdes \cite{Adams2009Conceptual};
%    \item \emph{citep}:Unicórnios são verdes \citep{Adams2009Conceptual};
%    \item \emph{citet}: Segundo \citet{Adams2009Conceptual}, unicórnios são
%                        verdes.
%    \item \emph{citen or citenum}: Segundo \citen{Adams2009Conceptual},
%        unicórnios são verdes.
%    \item \emph{citeauthor e citeyearpar}: Segundo artigos de
%        \citeauthor{Adams2009Conceptual} , unicórnios são verdes 
%        \citeyearpar{Adams2009Conceptual}.
%
%\end{itemize}
