\chapter{Theoretical Background}
In the previous chapter, we have argued that multiple robotic tasks would benefit from exploiting the semantic information inferred from everyday environments that surrounds the robot. We have chosen the object search (OS) problem to explore this idea, which aims to estimate a target object's location in a large unknown environment, usually with a camera attached to a mobile robot. We believe investigating this problem can expand our understanding regarding the benefits of employing semantic information to improve the robot's perception. 

This chapter presents a theoretical background detailing techniques used throughout this thesis. The OS problem requires the robot to map the unknown environment and to estimate its position simultaneously. SLAM systems fulfill these requirements, and hence, we address the basic concepts of such systems and other basic concepts in mobile robotics. Besides, we cover the generic and central formulation of OS problems, which is the basis for the works presented in Chapters X and Y [TO DO].

\section{The Basics of Mobile Robotics}
Mobile robots perform several tasks that require them to be aware of their positions in the environment and obstacles' positions to avoid collisions. In most realistic scenarios where the robots are deployed, such information is not directly available. Hence, the robots have to estimate it with their sensors, which provide noisy and partial data from the environment (CITE PROB. ROBOTICS).

The state estimation in mobile robotics can be summarized in four variables: 
\begin{itemize}
	\item $\bs{x}_t$: robot's pose at time step $t$. It is composed by a three dimensional vector containing $(x, y, \theta)^T$, in which $x,y$  represent the position and $\theta$ the orientation. A sequence of robot's poses from time step $0$ to time step $t$ is defined as $\bs{x}_{0:t}= \{ \bs{x}_0, \bs{x}_1, \cdots, \bs{x}_t\}$.
	\item $\bs{m}_i$: object $i$'s position in the environment. A list of $N$ objects, with $1 \leq n \leq N$, in the environment along with their properties is given by the vector $\bs{m} = (\bs{m}_1, \bs{m}_2, \cdots, \bs{m}_N)^T$.
	\item $\bs{u}_t$: control data at instant $t$, and it corresponds to the change of state in the time interval $(t - 1;t]$. The sequence of control data that takes the robot from the initial position to $\bs{x}_t$ is denoted by $\bs{u}_{1:t} = \{\bs{u}_1, \bs{u}_2, \cdots, \bs{u}_t\}$.
	\item $\bs{z}^i_t$: the $i$-th measurement made by the robot at instant $t$. The vector of all of them acquired at the same instant $t$ is $\bs{z}_t = (\bs{z}^1_t, \bs{z}^2_t, \cdots, \bs{z}^K_t)^T$, whereas $\bs{z}_{1:t} = \{\bs{z}_1, \bs{z}_2, \cdots, \bs{z}_t\}$ expresses the history of all observations.	
\end{itemize}

After defining the four variables that are the basic foundation for state estimation in mobile robotics, it is worthing to explain their role in different estimation problems.  The set of controls $\bs{u}_{1:t}$ and measurements $\bs{z}_{1:t}$ are always known since the robot's sensor provides them. Inertial measurement units and wheel encoders are sensors that provide control data, whereas lidars, sonars, and cameras measure the environment. The other two variables, robot's pose $\bs{x}_{0:t}$ and environmental map $\bs{m}$, are not necessarily known. Depending on the estimation problem, it is necessary to estimate different variables, like the three examples depicted in Fig. [REF THE FIG]. In \textit{Localization}, the map is known in advance, and hence, only the robot's pose is estimated. The opposite happens in \textit{Mapping}, as the map is built based on the robot's pose. Lastly, in \textit{SLAM}, which combines the two previous problems, none of them is given a priori, and therefore, both are estimated simultaneously. 

Localization is the most basic perceptual problem in robotics. It aims to determine the robot's pose relative to a given map of the environment. Localization can also be seen as a problem of coordinate transformation, in which it is established a correspondence between the map coordinate system and the robot's local coordinate system. (CITE PROB. ROBOTICS).  There are multiple localization problems, and not each of them is equally difficult. One characteristic that divides this problem into local and global localization is the awareness of the robot's initial pose. The former assumes that the initial robot's pose is known. Therefore, the problem becomes a sort of position tracking in which the noise is adjusted in robot motion commonly by a Gaussian distribution. On the other hand, the latter is unaware of the initial pose, making it perform the localization globally (where the name comes from) in the map. The global localization has a higher difficulty level than the local one, but one of its variations is even more challenging, called the kidnapped robot problem. It addresses the problem of a localized robot being teleported to some other location in that the robot might believe it knows where it is while it does not.  Although a robot is rarely kidnapped in practice, recovering from localization failures is essential for autonomous robots. 

The formulation of the global localization problem is presented in Figure [REF THE FIG], which depicts a few iterations of the robot's pose estimation and how the variables are used. The map $\bs{m} = (\bs{m}_1, \bs{m}_2, \bs{m}_3, \bs{m}_4)^T$ is already known, whereas the $\bs{x}_{0:t}$ must be estimated based on the controls $\bs{u}_{1:t}$ and the measurements $\bs{z}_{1:t}$.